{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adamm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adamm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>1</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>1</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_clickbait    dataset\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...             1  fake-news\n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...             0  fake-news\n",
       "2                  Why the Truth Might Get You Fired             1  fake-news\n",
       "3  15 Civilians Killed In Single US Airstrike Hav...             1  fake-news\n",
       "4  Iranian woman jailed for fictional unpublished...             1  fake-news"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if data not saved as csv, run this\n",
    "import os\n",
    "if not os.path.exists('data/merged_titles_labels.csv'):\n",
    "    df1 = pd.read_csv('../eda/small1/labeled.csv')\n",
    "    df2 = pd.read_csv('../eda/small2/labeled.csv')\n",
    "    df3 = pd.read_csv('../eda/small3/labeled.csv')\n",
    "    df = pd.concat([df1, df2, df3], ignore_index=True).reset_index(drop=True)\n",
    "    df.to_csv('data/merged_titles_labels.csv', index=False)\n",
    "    df.head()\n",
    "else:\n",
    "    df = pd.read_csv('data/merged_titles_labels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adamm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adamm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adamm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\adamm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\adamm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        House Dem Aide: We Didn’t Even See Comey’s Let...\n",
      "1        FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        15 Civilians Killed In Single US Airstrike Hav...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "74119    To Make Female Hearts Flutter in Iraq, Throw a...\n",
      "74120    British Liberal Democrat Patsy Calton, 56, die...\n",
      "74121    Drone smartphone app to help heart attack vict...\n",
      "74122    Netanyahu Urges Pope Benedict, in Israel, to D...\n",
      "74123    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 74124, dtype: object\n",
      "Removing numbers and replacing with words...\n",
      "0        House Dem Aide: We Didn’t Even See Comey’s Let...\n",
      "1        FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single US Airstrik...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "74119    To Make Female Hearts Flutter in Iraq, Throw a...\n",
      "74120    British Liberal Democrat Patsy Calton, fifty-s...\n",
      "74121    Drone smartphone app to help heart attack vict...\n",
      "74122    Netanyahu Urges Pope Benedict, in Israel, to D...\n",
      "74123    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 74124, dtype: object\n",
      "Removing possesive s...\n",
      "0        House Dem Aide: We Didn’t Even See Comey Lette...\n",
      "1        FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single US Airstrik...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "74119    To Make Female Hearts Flutter in Iraq, Throw a...\n",
      "74120    British Liberal Democrat Patsy Calton, fifty-s...\n",
      "74121    Drone smartphone app to help heart attack vict...\n",
      "74122    Netanyahu Urges Pope Benedict, in Israel, to D...\n",
      "74123    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 74124, dtype: object\n",
      "Expanding short versions...\n",
      "0        House Dem Aide: We Didn’t Even See Comey Lette...\n",
      "1        FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single US Airstrik...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "74119    To Make Female Hearts Flutter in Iraq, Throw a...\n",
      "74120    British Liberal Democrat Patsy Calton, fifty-s...\n",
      "74121    Drone smartphone app to help heart attack vict...\n",
      "74122    Netanyahu Urges Pope Benedict, in Israel, to D...\n",
      "74123    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 74124, dtype: object\n",
      "Removing punctuation...\n",
      "0        House Dem Aide We Didn’t Even See Comey Letter...\n",
      "1        FLYNN Hillary Clinton Big Woman on Campus  Bre...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single US Airstrik...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "74119    To Make Female Hearts Flutter in Iraq Throw a ...\n",
      "74120    British Liberal Democrat Patsy Calton fiftysix...\n",
      "74121    Drone smartphone app to help heart attack vict...\n",
      "74122    Netanyahu Urges Pope Benedict in Israel to Den...\n",
      "74123    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 74124, dtype: object\n",
      "Replacing US with USA...\n",
      "0        House Dem Aide We Didn’t Even See Comey Letter...\n",
      "1        FLYNN Hillary Clinton Big Woman on Campus  Bre...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single USA Airstri...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "74119    To Make Female Hearts Flutter in Iraq Throw a ...\n",
      "74120    British Liberal Democrat Patsy Calton fiftysix...\n",
      "74121    Drone smartphone app to help heart attack vict...\n",
      "74122    Netanyahu Urges Pope Benedict in Israel to Den...\n",
      "74123    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 74124, dtype: object\n",
      "Tokenizing...\n",
      "0        [house, dem, aide, ’, even, see, comey, letter...\n",
      "1        [flynn, hillary, clinton, big, woman, campus, ...\n",
      "2                               [truth, might, get, fired]\n",
      "3        [fifteen, civilians, killed, single, usa, airs...\n",
      "4        [iranian, woman, jailed, fictional, unpublishe...\n",
      "                               ...                        \n",
      "74119    [make, female, hearts, flutter, iraq, throw, s...\n",
      "74120    [british, liberal, democrat, patsy, calton, fi...\n",
      "74121    [drone, smartphone, app, help, heart, attack, ...\n",
      "74122    [netanyahu, urges, pope, benedict, israel, den...\n",
      "74123    [computer, makers, prepare, stake, bigger, cla...\n",
      "Name: title, Length: 74124, dtype: object\n",
      "Lemmalizing words...\n",
      "0        [house, dem, aide, ’, even, see, comey, letter...\n",
      "1        [flynn, hillary, clinton, big, woman, campus, ...\n",
      "2                               [truth, might, get, fired]\n",
      "3        [fifteen, civilian, killed, single, usa, airst...\n",
      "4        [iranian, woman, jailed, fictional, unpublishe...\n",
      "                               ...                        \n",
      "74119    [make, female, heart, flutter, iraq, throw, shoe]\n",
      "74120    [british, liberal, democrat, patsy, calton, fi...\n",
      "74121    [drone, smartphone, app, help, heart, attack, ...\n",
      "74122    [netanyahu, urge, pope, benedict, israel, deno...\n",
      "74123    [computer, maker, prepare, stake, bigger, clai...\n",
      "Name: title, Length: 74124, dtype: object\n",
      "Removing non ascii characters...\n",
      "0        [house, dem, aide,  , even, see, comey, letter...\n",
      "1        [flynn, hillary, clinton, big, woman, campus, ...\n",
      "2                               [truth, might, get, fired]\n",
      "3        [fifteen, civilian, killed, single, usa, airst...\n",
      "4        [iranian, woman, jailed, fictional, unpublishe...\n",
      "                               ...                        \n",
      "74119    [make, female, heart, flutter, iraq, throw, shoe]\n",
      "74120    [british, liberal, democrat, patsy, calton, fi...\n",
      "74121    [drone, smartphone, app, help, heart, attack, ...\n",
      "74122    [netanyahu, urge, pope, benedict, israel, deno...\n",
      "74123    [computer, maker, prepare, stake, bigger, clai...\n",
      "Name: title, Length: 74124, dtype: object\n",
      "Removing empty titles...\n",
      "0        [house, dem, aide,  , even, see, comey, letter...\n",
      "1        [flynn, hillary, clinton, big, woman, campus, ...\n",
      "2                               [truth, might, get, fired]\n",
      "3        [fifteen, civilian, killed, single, usa, airst...\n",
      "4        [iranian, woman, jailed, fictional, unpublishe...\n",
      "                               ...                        \n",
      "74119    [make, female, heart, flutter, iraq, throw, shoe]\n",
      "74120    [british, liberal, democrat, patsy, calton, fi...\n",
      "74121    [drone, smartphone, app, help, heart, attack, ...\n",
      "74122    [netanyahu, urge, pope, benedict, israel, deno...\n",
      "74123    [computer, maker, prepare, stake, bigger, clai...\n",
      "Name: title, Length: 74118, dtype: object\n",
      "Removing stopwords one more time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamm\\Desktop\\sheeesh\\pracaInzynierska\\modelling\\functions.py:259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['title'] = df['title'].apply(lambda x: [word for word in x if word not in stop_words])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[house, dem, aide,  , even, see, comey, letter...</td>\n",
       "      <td>1</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[flynn, hillary, clinton, big, woman, campus, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[truth, might, get, fired]</td>\n",
       "      <td>1</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[fifteen, civilian, killed, single, usa, airst...</td>\n",
       "      <td>1</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[iranian, woman, jailed, fictional, unpublishe...</td>\n",
       "      <td>1</td>\n",
       "      <td>fake-news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_clickbait    dataset\n",
       "0  [house, dem, aide,  , even, see, comey, letter...             1  fake-news\n",
       "1  [flynn, hillary, clinton, big, woman, campus, ...             0  fake-news\n",
       "2                         [truth, might, get, fired]             1  fake-news\n",
       "3  [fifteen, civilian, killed, single, usa, airst...             1  fake-news\n",
       "4  [iranian, woman, jailed, fictional, unpublishe...             1  fake-news"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run functions.py\n",
    "if not os.path.exists('data/preprocessed_titles_labels.pkl'):\n",
    "    df = preprocess_title(df, verbose=True)\n",
    "    df.to_pickle('data/preprocessed_titles_labels.pkl') \n",
    "\n",
    "else:\n",
    "    df = pd.read_pickle('data/preprocessed_titles_labels.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sample'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['sample']=='train'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sample'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "EPOCHS = 500\n",
    "WORKERS = 16\n",
    "MIN_COUNT = 1\n",
    "\n",
    "\n",
    "# train many word2vec models with diferent VECTOR_SIZE and WINDOW\n",
    "\n",
    "VECTOR_SIZEs = [\n",
    "    100, \n",
    "    250, \n",
    "    500, \n",
    "    # 1000, \n",
    "    # 1500, \n",
    "    # # 2000, \n",
    "    # # 2500, \n",
    "    # # 3000\n",
    "]\n",
    "\n",
    "WINDOWs = [\n",
    "    3, \n",
    "    4, \n",
    "    5, \n",
    "    6, \n",
    "    7, \n",
    "    8\n",
    "]\n",
    "SGs = [0, 1]\n",
    "\n",
    "\n",
    "##################################################\n",
    "# # --uncomment for sample model training--\n",
    "# EPOCHS = 200\n",
    "# VECTOR_SIZEs = [500]\n",
    "# WINDOWs = [4]\n",
    "# SGs = [0]\n",
    "##################################################\n",
    "\n",
    "\n",
    "print('Start training')\n",
    "# sleep 200 ms\n",
    "time.sleep(0.2)\n",
    "\n",
    "for VECTOR_SIZE in tqdm(VECTOR_SIZEs):\n",
    "    print(f'Current VECTOR_SIZE: {VECTOR_SIZE}')\n",
    "    for WINDOW in tqdm(WINDOWs, desc=f'WINDOW'):\n",
    "        for sg in tqdm(SGs, desc=f'SG'):\n",
    "            # check if model already trained\n",
    "            if os.path.exists(f'word2vec_models/word2vec_vs{VECTOR_SIZE}_win{WINDOW}_sg{sg}.model'):\n",
    "                print(f'word2vec_vs{VECTOR_SIZE}_win{WINDOW}_sg{sg}.model already exists')\n",
    "            else:\n",
    "                model = Word2Vec(df_train['title'], vector_size=VECTOR_SIZE, window=WINDOW, min_count=MIN_COUNT, workers=WORKERS, sg=sg)\n",
    "                model.train(df_train['title'], total_examples=len(df_train['title']), epochs=EPOCHS)\n",
    "                model.save(f'word2vec_models/word2vec_vs{VECTOR_SIZE}_win{WINDOW}_sg{sg}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vocabulary\n",
    "with open('data/vocabulary.txt', 'w') as f:\n",
    "    for word in model.wv.index_to_key:\n",
    "        f.write(word + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
